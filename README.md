# bachelor-study
これは畳み込みを用いないGAN(Generative Adversarial Networks)の新たな訓練安定化手法の研究用コードです。
深層学習を用いた画像生成の分野において、従来のDCGAN(Deep Convolutional GAN)では困難であった高解像度画像の生成手法としてPGGAN(Progressive Growing of GANs)が知られています。PGGANでは訓練の過程において畳み込み層を段階的に追加することで、画像の解像度を段階的に増加し、高解像度画像の生成や訓練の高速化、訓練の安定化に成功しました。しかし、昨年画像認識分野にVision Transformerという畳み込みを用いない学習モデルが登場しました。また、今年の2月にはVision Transformerを用いたGANである、TransGANという論文が発表され、畳み込みを用いない新たな訓練安定化手法が求められています。
私はPGGANにおける「段階的な画像の解像度の増加」を「段階的な画像の情報量の増加」と捉え、解像度以外で画像の情報量を変更することで、畳み込みに依存しない新たな訓練安定化手法が確立できるのではないかという仮説を立てました。また、画像の情報量を変更する手段として、圧縮技術に用いられる画像の周波数分解に着目しました。
私の研究では訓練画像に周波数分解を行い、高周波成分を削減した低周波成分のみの画像から訓練を開始し、段階的に高周波成分を含む画像に変更することで、訓練が安定化し生成画像がより高品質なものにできるのではないかという実験を行いました。訓練には一般的なDCGANのモデルを使用し、周波数分解にはJPEGの規格に準拠したDCT(Discrete Cosine Transform)とJPEG 2000の規格に準拠したDWT(Discrete Wavelet Transform)の二つの手法を用いました。卒業研究では解像度が32×32のCifar-10データセットを使用し、IS(Inception Score)にはあまり変化はなかったものの、FID(Frechet Inception Distance)という評価指標で、周波数分解を用いなかった場合と比較してDCTを用いた提案手法では数値を10パーセント程度低下させることに成功しました。現在は別リポジトリにてCelebAでの実験も行なっています。
今後はより高解像度なLSUNデータセットを用いた実験や、実際に畳み込みを用いない学習モデルであるTransGANに提案手法を適用してみることを検討しています。
周波数分解はDWT, DCTにのみ対応しています。(FFTは試験的な導入であり動作しません)
